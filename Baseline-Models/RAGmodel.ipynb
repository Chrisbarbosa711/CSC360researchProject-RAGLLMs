{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chrisbarbosa711/CSC360researchProject-RAGLLMs/blob/main/Baseline-Models/RAGmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Mini Retrieval-Augmented Generation (RAG) System Using Gemma-3 + Wikipedia\n",
        "\n",
        "This Colab notebook walks through:\n",
        "\n",
        "Using a Gemma-3 model as a lightweight LLM for generation.\n",
        "\n",
        "Building a RAG pipeline using\n",
        "\n",
        "Wikipedia dataset (HuggingFace)\n",
        "\n",
        "Document chunking\n",
        "\n",
        "Sentence Transformers for embeddings\n",
        "\n",
        "FAISS vector store\n",
        "\n",
        "Running example queries from earlier.\n",
        "\n",
        "Monitoring simple latency and token-count metrics.\n",
        "\n",
        "Highly documented code, suitable for training, demos, or prototyping.\n",
        "\n",
        "This notebook is fully self-contained and runnable in Colab GPU mode."
      ],
      "metadata": {
        "id": "b5jPrPkrP1p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import json\n",
        "\n",
        "path = \"RAGModel.ipynb\"\n",
        "\n",
        "with open(path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "widgets = data.setdefault(\"metadata\", {}).setdefault(\"widgets\", {})\n",
        "widgets.setdefault(\"state\", {})\n",
        "\n",
        "with open(path, \"w\") as f:\n",
        "    json.dump(data, f, indent=1)\n",
        "\n",
        "print(\"Added missing 'state' IN-PLACE:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "OrjSvD1Ufaex",
        "outputId": "22c97f1d-2d13-427d-c16d-1b98fd5c9abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'RAGModel.ipynb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2634203359.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RAGModel.ipynb\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m    \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RAGModel.ipynb'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lieTNUurLrUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc84c2e-4891-4bb5-bb1d-28417f9e37a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/566.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m563.2/566.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets sentence-transformers faiss-cpu langchain accelerate langchain-community tokenizers torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Wikipedia dataset is very large (many GB), so for a simple prototype RAG system we will:\n",
        "\n",
        "Load only the first 5,000 examples.\n",
        "\n",
        "Extract each page's text field.\n",
        "\n",
        "Perform simple chunking (character-based) into ~500–700-character chunks.\n",
        "\n",
        "\n",
        "This gives us enough material to test retrieval & generation realistically."
      ],
      "metadata": {
        "id": "psRi1ESQQH2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load small subset to keep memory + compute low\n",
        "# The 'wikipedia' dataset script is deprecated. Use 'wikimedia/wikipedia' with a specific configuration.\n",
        "# Using a recent English snapshot '20231101.en'.\n",
        "wiki = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\", split=\"train[:5000]\")\n",
        "\n",
        "print(\"Loaded:\", len(wiki), \"Wikipedia pages\")\n",
        "print(\"Sample page:\", wiki[0][\"title\"])\n",
        "print(wiki[0][\"text\"][:500], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "08bc00f1a80b44a79e5571f1d8a61d6a",
            "23f79a1938dc4e98ac74ba00694b9cb1",
            "6fe346239f864a65917c0e437ca70f39",
            "12955e9521564a78a07aa1cc632cc777",
            "2476abab85ba46d9af8b5c07c9e55685",
            "eb1bc9580e694b50849a7f69faf124f8",
            "214026ce0f3d4c168404d1a250def296",
            "fbe91e97d4fb4bde95be3e0e04605ce4",
            "5a0e3dc344654b38bef10f133aa15e91",
            "483d57c014094c25b220e6b1b6127dc1",
            "56fbc10123da4d658c762f0c4fac8414",
            "da56cac4c7c04d9ebe9ff776871abc90",
            "8d0090550b584e6dae9004cd2913d3ca",
            "0d9ee51934494809b55206b6e945d1ba",
            "1b2b142eb04441b294513b00d15011c7",
            "c9f71175d36f42e4a75cf5e9eb5dbd1c",
            "ed8d4f02002944bb90afe1d4562bc0c4",
            "3c08ae53359b41aea34908bcb69d284e",
            "cf3079e4b5a247d89dde8b06b9232cc5",
            "d0ccc7155717468d85a21e6fe4540c16",
            "3ece4564938a4edd8da83e7baa96c68c",
            "49bdb149b2544124b88f435674d37bc6",
            "b6ced3e696144e1389f81780333a73ca",
            "2832e4cbc44f4293ac85c35346c36854",
            "be2bace3edda405bbcfb9d3c33b03661",
            "86551c4deb50431bb51054e670e108e9",
            "c64b1c47ec3545f6ba336077ed0988d5",
            "23a44f8deb4c4fe99f7b7eb8301b91fd",
            "24c54331dda7400987746231f4e75c0e",
            "c32e18209e2a43a499364458e0ada2f3",
            "d60653cd720d4717b0e6d6203ee08621",
            "03af1b2b1c54467ab7aaed5ac6c0445f",
            "8e39ddf2a972451fa4f52a7fc318d9c7",
            "8b909b6e40594508a0c43bce11141350",
            "2baf9b322b234d05ac47cde74477c7f8",
            "00a15a190bbb42489f8ea67e9fd2a060",
            "7f12bcf1864847edacbbb9bc69ac7fa4",
            "fb7c3a3c6fab42f28f0af98f370d5eff",
            "87c0d4b368f548068ddfb9bf2551c967",
            "d5d6a66337a24730a48a628edd6f2341",
            "d5bbf6b61c034c5d86d6420f05943ee0",
            "75a766d8574f4800b7dd5e3809032e50",
            "d737fb0506784f4297392e42f9d7a96b",
            "8d1f355e43a44875a7e155d9db65d91e",
            "ea4d4e6bda6b41db9b4b2f4a7e2c87e1",
            "73285b47deea48dd865c5c22db52bc46",
            "c37495c1b64543dcae77aacb35015630",
            "d631469af7bf42be860b053e9b0334ac",
            "3135dc47103a493d92fc5de56ce5cbfc",
            "cc6161a449f2458e8476d3f4966d6f06",
            "444f6b601b7f472aa202e8af6e17cadc",
            "74b0059d69bf4d0d83a34333064012b2",
            "2eb1f84f0c224ac998f94005815e445a",
            "bf373df736d94a68aabbfc7eba6c0dd0",
            "e31897439b0d459dbe9289e55f78f03e",
            "97149ea2677e4010b6a9619bc252277d",
            "44f95a82e47647ff8f2b2808786d3b02",
            "8d8bc72de728463e832637c26c2436ca",
            "f0ce266129824d228785163291c069b4",
            "1c0bb5b7da764d798b8572b2605a30c3",
            "0cfe026696a04f5f9ead6627e2aa05c5",
            "2b5daef516c34036bd5e937bd583be0c",
            "d62289e57ab44e91ac8e3e4cce9150a1",
            "0604a54d661d4862adf84f21e02fb226",
            "72fa1cdc26bd4883af703a2a2296638e",
            "1dd8a201516f44ebb6d9f29250b3be6d",
            "1abe937a3eec48848e7c851278215f0a",
            "c969d8b8c1f94c1ea7320026f2f8feb1",
            "d82f65ada66742a6b7a50f5dad060476",
            "ec0118817c504facb76e42a2282d406f",
            "e9da2cc775764fe79b9eb98cdd022194",
            "d569148a554846fab20e5e1360406611",
            "84c3ee0db47d4bb49feac67e3706a7bb",
            "875b0991af2a4edfb06101642d8821d0",
            "974720f8fc0c40c3af9ce7b10cafd8e6",
            "8f8f2221ef9d4a53b9d4eb3f0c7bab86",
            "232e64d887544b0d9650f2bdf7100854",
            "ab7c129d81c24158b1169ce1372af650",
            "1555420b76734b83b0657e2740b71b82",
            "22dd73edfe704c08b1a6466d36647614",
            "6b313b0f44e74644a311dccdd4575604",
            "d4d22f8a3ac546e4afbacbf7036a9c07",
            "7052df503f5047b49ed62089f5b9835f",
            "9dea649744004c0ca7639e6824bd3949",
            "5d3513dea25c4507ad54e92aa7184db3",
            "b795819d974946cdb4b8accaca8a97fc",
            "b170279701324018b21093a9e8dc14c5",
            "c838e5d7975d455db7c0d6387937611d",
            "da1b47d8091a46fcab7ca792a2144628",
            "15b60425b3414236aba79f2c63604bfc",
            "121a5d1ea871401d9128b07974ca43ec",
            "02e4f95521a44ef6b53c63225f632b9f",
            "cc24ffe6535742b3a7d031e612ee0e0f",
            "66391453d3284a6f80de2aa5814a3c32",
            "46cc80b865cb4a8da32f035ee7144add",
            "801af5978df84c2d8a5ca7c5893f7c78",
            "56ef357601e0443c9fb3ca7d80bb775d",
            "0f3b465ce9eb43a4bb1759bcb565eb02",
            "a413b30863c54a4bbee84f631fb79342",
            "6960eedba671403cb138d64f43d411a4",
            "a55561b5c836453e82fb06b77c328029",
            "73cd1e57443e477c84b50311648f2e1c",
            "7bb6a032908d4343b7e5944dd4827a93",
            "7ac9f6f2ba4d4ee4958a4d6292ea4f03",
            "a679c6d916804f30b60f45f47c551cd3",
            "156d4881adf14148a0da380a1afa9742",
            "4637908cd20e481a8d0c186c2b18b6b8",
            "8bcb4e39cff54c799936819b9c7179d0",
            "4bc6d09f9b87471a86ee68fc529ee7d6",
            "b74c295c7cf449e7ba7c98ba52db61a7",
            "236be4e2a67f439696574848f49858f1",
            "1ea43a88865d455db10b971198440ff3",
            "c64e10eb290242ed8fbc8ab9eca742ef",
            "6e6e3439f178446aa33e287946bdbb40",
            "c93bde3a100a42099a4ec5ecacfb091c",
            "b03b870e16614180a9effc47f4527ef0",
            "09bcdbc3f1c943d39c890b11319029f7",
            "2d6a0dc087244bc9aa166f3013e9ab2a",
            "75759628ee2b49aa8731237ce359b48c",
            "17f440149480495b97b00b9774aaafd4",
            "76022b776cf44c61a5df4f057673dd48",
            "8ea74a54d5bd4a05a72ea66adc45c4ff",
            "37f40d1cb2a44032a191e43c169c73d9",
            "af2f7ec3c1a44d9ab79e9bc7cb52c84d",
            "4ca0f55b28d94f53b80a2eb503022a44",
            "7dad580d643841a19a7150a57d9f1be8",
            "1b4e2984669b4a18b89f4443be6ea3ad",
            "ad89a9c460754a72bde86fbc508a6d04",
            "d07707b3e63c46819cdce68ca2a4b41a",
            "91c20b854f41402b9037aff528ab4f62",
            "ca4b873bb90e4341ad7721fff8a9c6a9",
            "77f19c23724147c49d64ccdb3dbc24c9",
            "453d2115fdec4e14992f162369e3095e",
            "f7a20a6fca8b4108bcdbe7aa294e86b9",
            "1909ea551a4740b6838b0f165418d34b",
            "de35fd5bebdf4140b495e9f462acb0c7",
            "371a88bc41ea46b1a2c288932d4f5f41",
            "a8e7c5c687db4d47ae7313ea283b5a02",
            "a0ba073437314a8abfd39cc73628f441",
            "72c3a43867e0409a85c7e8224c3f0537",
            "e9f94bffb9d445159a0b4a78a636b443",
            "93948266411341a7a694401c2de8bca3",
            "4d75e4ee2dec459084ed8e200356f153",
            "fed91a1267f14dc19b449c09ff34b136",
            "bc88efc7d58f42aa992c820b913623dd",
            "30edfc100e0e44cca65e997771895211",
            "305194d341d546159ed82ae21b16655d",
            "85742064b1c146fe978f7e99a38c423c",
            "97e47dd8b943453fb74e009fe2bd017b",
            "59d2bf9d4aca40c4ac4ad8fcc7c2a3b6",
            "31605df4b7654e38bffd4d0110b543c3",
            "98f4f28039354aed8497256b76529fdb",
            "0a9a8e17ed9140eda8fda810b1c8c278",
            "f0e4c9500b2b49f4b56a71225086cdd1",
            "00686fa5e7684241881b119288c5dd47",
            "6dbe07528109430c8e4ebdd5fe95f092",
            "8b9fb90660fe44b9b6dc50ddb4419262",
            "8db1fec05e1e4beda2d5e32f1209b2b5",
            "e7906e5f04d04c4c83f5db7af2259dc8",
            "4e5cef4ae7bf460f8ff599e4e4dde8b3",
            "c40100d296a245a085c1b92c146420e9",
            "43eee3da88ee4958b5d09c6be8ef3a21",
            "f737699075f14515b0ced65dc7845986",
            "6ee6315bc5e146f081c8ff02ff87796d",
            "e16ab59e83d740a5a24054d3ce607774",
            "ffe12739182c4d78ae3bd47cc63918ec",
            "a90cc758137a45f7a323e68ab55c7919",
            "faa1c5c7ad004108a93afa468c0e2dbf",
            "ab313d56b7554298a3aecf813a0eede5",
            "1a041e2af36b43eba54ed4c407bc7368",
            "0f661d46ee424ffca3fd16b039f97445",
            "468d634b35414033bcb776ea984c8ced",
            "a95078b550824f478645e1a122157ca1",
            "0d1d466795ab4caf9802c37f499e426f",
            "32e099cada4149eeb283d672c2b9ea72",
            "fd5f5d93c6f1489ea50bbd8b97428e31",
            "23cbf53cfefa427ebcddd28fcb679318",
            "48f374addf8347a28a4535a7dbd15c4d",
            "2b05a5b0a3a141179b8b58aaa2d1d484",
            "369e65bd90824088993c30bbc9ea5018",
            "d14f7713f4464eaaafdfea0b7964165b",
            "a3485aedcfeb47ddb4491834cbc062f3",
            "386901045e324b1cbb5633032ac05215",
            "99f0ebdb96d84647990995a38cdf7d74",
            "492bf0319fca405a8beb0d8f03588b6a",
            "e80d18cd12e04ca4bab4eb1e4a61a25f",
            "4f48a26a7b084f1fb74387463663510a",
            "f02d81549a62428d9835701ea469b829",
            "2ed2bcb8a29646dcbc046ffd4502725b",
            "4790eddf42794f72b1a96af7d8908129",
            "fa5041a42f0f4452b6900b85e60a3fb5",
            "47a6253668814d72ba66e1526a21dde8",
            "d1274f301be243408522d561bcd2273d",
            "5161ef68da994ca681ee8a4bccf0b200",
            "db7c7abe087848de861109e5950c237b",
            "8dbb0e17c5d64af589d2984f3632e79f",
            "97772d8b0b7943f5bd600f0617f5cc5c",
            "7af7f9eb82c54a599a6260fa5fa3e3fe",
            "22f1b7aebecd4fffb56293345ea1b57a",
            "ccb6e9dfe9ba4b0caad80bd78d27cdf4",
            "37d59b8b772a49e08141306317facd4d",
            "bedcb890ec92422e9457337ba708ad7a",
            "63c95b9678954146964a8a3b5f25793f",
            "b24dd9fe84b944e7bfdefe6d83da8cdd",
            "ddfdc50e7afc493a98e44c785213d760",
            "f8d0e9a1f20349dc82941dd2453da6f3",
            "2ae8796310b64770b6645368eb45c0dd",
            "2168e2c3d44f4edd9073dfc567c331c3",
            "943f5687f0b44cff83e4d2aa8f1f8942",
            "0e7787bcb2c64d44ae1ff498ea543176",
            "f7b916ebc15848b4841b3dfe5d2ec7d8",
            "a5f0dfcd47044933a1920ef242cf005b",
            "f79a10e50fc043f3a7009b756d0e4ca3",
            "5af8b99bf4724c7bb2da31b56ff2206e",
            "923ef80265494a3d87ff659edab62279",
            "599768b3e542491683e0513aaa6a972b",
            "acc650b1c4394ccfa9d5cfc64a44c51b",
            "09cb359a9f454e98bb94ae97fa25ad96",
            "03a4cd9012444b0c9836ad2e589a6479",
            "62885625007e4b6ca3508708f79cac15",
            "99717cc88b184841b58ebe738d40193f",
            "8b195a33063b4cfcb0a5818cdfddf6f9",
            "dd82ddbe7b9d444da433bbe4b1c78fcd",
            "22fb8d8d8b5941a5afa153b1abf938a6",
            "55d2b963b5e84188a629c74717c235c9",
            "7c09ca5eb0174b908e8a1761105ce5d3",
            "8017d842501d4adfa26d7408614b005a",
            "78017abd879c4bdb865c4c6a8903cd86",
            "7e07d92e6e1e4461a1305d4e50aeeef1",
            "23e260dccc63492d92f7072ab02c060e",
            "4b66d7ada3e549b28eba6697dbd6e774",
            "e7fa9d9af2d441ed9466aed31eee6aaf",
            "c8ba4584f7664d4cb914c161987d0f66",
            "b161f43c116c43df92127aefc323ae97",
            "40f292f2f3c54b2297eb859e51a23fd6",
            "581f1f9a95ee4afcb417084382248686",
            "e2050949b8ba45ae8e2a6735fe1a8fd4",
            "7ff1f1737b5342878816e59468781404",
            "d51d1a6aba18459b951d79bef9ea1011",
            "0ddfdfb80249405b82393c206dfe3249",
            "c342c10d52b745dbbef8a281f4177fa2",
            "edbc4cd75c1f4ce08a0b744d9dca2738",
            "1de2b99d922c47ef805c4996a0049fc8",
            "ba95c11d158e47afa86698f35c3e324e",
            "b4d8fef1cc3d48e9b8f5428f07384e79",
            "8f408d519cf3481dac35af99adfe61ef",
            "00b65e7d132045b5a6d5e8c38dd39f3a",
            "70b0e0ae63be4828b1bb5b98e0ece607",
            "f197cf41390c4c7eb108f7e0ca86d0b1",
            "4aad147113ce48fca7d6ab29891b66ae",
            "55aa8178a115418982e0ee1901c62b90",
            "de9aaca888c9479c93b85ab4c223015b",
            "0b6420b86ae24ddab3f3d04b7b720a49",
            "f5525e38849d4b06be38dbf6d69b56d6",
            "ddf9a5a35038482895c1566eb5cb06bf",
            "ce7d5a8bcfaa44a999bd57ba9f1c3a82",
            "bd5b35ca31c3448ca541986d75646017",
            "88a7f5316d084f8b82fff06445d9eb5b",
            "14ca53be2b6048739f1bd373b5d1ac8d",
            "a2f3613fd4b04bd7804b907b22b57531",
            "cec7ec74f3ca4e03a8743646438c6dca",
            "17f570efa6fe46c689223c9fb0b1f6ef",
            "2fdf64f10f1a4362a61dba67bb4e7d39",
            "1b50ad2c62564e4cad2bf08f4c91f0b6",
            "a537ae83747540c2b54d88f59de558ba",
            "d38d1a1b89eb4cf8b5e8fc6184d6b701",
            "4107bd8fcf9849968c37de11baf3b490",
            "a962c00ce3e94226811ff8d2d02cc78c",
            "3587e537fa7048e095e91e54d1f64e4e",
            "e0ed43c39444462db4ba17fd2af4f2bc",
            "9e5341f5d88043acb3771ddefc0e156a",
            "5f8e9b13ca744b97b6b9f42be13bb0e8",
            "1335117eb7fd4d48a27c0e0eff96f1d8",
            "1f761dc8b5cb45ebb4ae20253b83c1cc",
            "c6158b18670d474894cf883e292258a4",
            "43e3f920b3ad4fe198cb49a71a4a3aab",
            "4487e8bad6c5405db9082d77a7181ba7",
            "aeeeb585bee94123b1b2b0b0900458b3",
            "d0d63e05205c452d8e7569645a8e5b1e",
            "08583b9c45064edfb35cb93e35297090",
            "0d1798f2f680447fa62e2ae4d2ae8731",
            "0e635da00383494f85a7c5cd66f4831c",
            "67c64f4186494cd08130e09039a6a4d8",
            "3cd069e04b604c978fdf97b8f0a97743",
            "740859119eac4b0d8ea3d3a706709bcd",
            "f1f2f2b80fb64d3089d3cdfe722c9e2a",
            "862ccd7856f244f0a2a3cac391c8700c",
            "8e3101393c54406cbfac7eb5449a7f9c",
            "76a5b6c03a204620a57b09b70d47e95c",
            "4e76b9ff2bc346e5b39c326bca1e145c",
            "4bbe66e5c85d40cf851de91be6e43b62",
            "1030e5ca55104fd496d92761b887c472",
            "c3d43af6b7a1409d889e9bba7c36bfbd",
            "afc4780bc20141078ac533a47bf9d461",
            "87ab5f5916ab4168b32aae3554c49375",
            "2e179477aaca4b5f9bea9be734b96e70",
            "acdf102904a24d79bf2625c119f7850d",
            "a843e7a9a94c4ffdb041c0dd6e70e76f",
            "770a39c1d33847c59f26f4d07822af2f",
            "6f540e364f5b4bdaaeeffce0b3f7722d",
            "0806108e0b0e4f9d86abdb2a9c8ff9d4",
            "4f51576b22be47ec913c6e5e7d37b677",
            "ab21b9c4976544b2a8688b44b741cd73",
            "9193f2e2935b45e0a2abb5b8881caa65",
            "64f3049c1cc041dfa2604cad7c77f03a",
            "819503a3911c48d7aff3882e853432a4",
            "3bfcd6015aaf4dd0892ae601796dbdce",
            "3f5d581bc9db4833b6ea038aa2cc207c",
            "34b754ec5b6741bdb80e44a244f11199",
            "22fb269448c64ee6afe42712795628c7",
            "5b1e22f4d8884020ab85658455f53633",
            "131497b8665f423fbee791ad68494818",
            "a07642acd8534691a83fe7da7e1d6356",
            "b711155b7d7a443d85b3e9390c3f57fe",
            "c11c781851a8487a93aa5a83b323a449",
            "5452830a533943c7b59387c4f7c42ee2",
            "67db68c8de32463ba51c43e50bcb420d",
            "2bc0d08d35af4ff39bc6dab4192d6b8c",
            "6e18428353e64cdca9dd0e182b9efcc4",
            "98adba4b5ec74c5eafafd5212490f204",
            "cb4d65086c3e4047ae77da7f90f0d194",
            "1dbfb1a33f254e9faeb58f092398a248",
            "53e0dd7e4619409d92ba179c5a3dfc97",
            "4055bf786c0447f5b5c3fee0044d0352",
            "b8bdf049ce0340c48b8097aadc6155bd",
            "f13bea85e12e456b9d8998641bbc5c1a",
            "06f188eb921b47c3b86ef40792b1e3d6",
            "676a684c622d4c3d92501bf1fe944014",
            "e9b58dde60484c029411e4a94a6a7f74",
            "1df09240ded8492899da0330d86c02d3",
            "819bb85691fc430c85b8cd72dc7f3f22",
            "998ba27fcc904df4b446c509773b97b9",
            "c74b0f685d084525844306dcb1d96afa",
            "ab1dbbc3cefb4672b60d48f050d42a48",
            "2e32e840e63242af8e55a5519d6d3e05",
            "f9e57639c7774077b00d521ab475d6c2",
            "c27482f4ebff46bf9b3bf20a76a05c9b",
            "f024f5a5916149c4bcc545ae7259713a",
            "9d471734b58e44fa8e674b13123bbfb4",
            "a5ff9e5eea0c41b5b38341bfac4212bf",
            "d76e6b3e5e094d428fd5e222b5f9b198",
            "c89590613872439fa134c0efbc930e29",
            "84cc8a3556534224b5b020378d113c91",
            "7b92e180ef184c9db87f972a0a291504",
            "96279539b98d47ea996709dac54a04c2",
            "3088834e1eb34a41a44b8b8d3f3ab49d",
            "53704d5f1cf74b3b9162f9fe9fb23b52",
            "e1c3ec25547840f9937b6bd92e9eb3b0",
            "c5a26888ff004f8a9b528264d2ed1913",
            "806ce94bc6684743ad605b55f4b15462",
            "fd5cc0b30c7a4a5d9919c53f66337b3b",
            "81c4115787994956b99186ff9670a658",
            "407a8aae48074e2a90edd6d49a9eb2ef",
            "60ba7d319f034196b5f9bf0710b9432e",
            "6f9a7d644a164264b4be2dadcbd8d8f3",
            "a68138a77e1a4c8aac38ec4e7836c054",
            "05a0631000e648b2940cc31aac685491",
            "f82d3d95d0d74d049c4487c65f4881bb",
            "1f2d446588ea4d798ea146cb8c3690c0",
            "d52229853c0e4b09b6b3f0eb5d527baf",
            "43e71b9d9d9b495fb5b5991545b0f158",
            "add339dd463e498c88ca6e94ba05387c",
            "8d33aaa56e6a40af9c7c1c12edf5980e",
            "9bb3b8145c6f41f4a3f23e895ff74359",
            "59550e10e9df49bfa5eeaa10f4794f5d",
            "828909a4b786490c869de72c96def9af",
            "2bd105c3500340d8acf01cbbcdfe05b9",
            "fdfae6ade43c4d3e96670e65a848cd64",
            "692053df7fde4a91b55eba8a165b6b00",
            "7120410bc9254874beaf1749805e3e63",
            "7386bb5fd6d84ac095fd6ca615b3d911",
            "338d9f9941e3424eb066f2063cb3f905",
            "91260e7fcb73468b857c1575833c1ada",
            "98afb2f30b9849b8b4b8072ebb0e4fb3",
            "f6df658caa4244c7805ecc7a60aee7f3",
            "7b314683a5ad4fd28d2d1d91be7fc8e2",
            "af6a22318e514984a95d45f6d3059906",
            "94facd7ebf344ade8db3465c7c49e265",
            "dc09854659864e94a8b7d4b3cab84bfa",
            "2441a154c486439ea966f8a355c69818",
            "e8306fb5d7154da09fbffb3374dcdb19",
            "ffdb1554fa764c67b5dbed6fa42eefad",
            "e4a4b3bf9b9d45ee9d6a039e6bef2fa9",
            "b8a6dd83c11f4988a84e1fb4b544fb48",
            "e780327bc5bd4143a61e645fa3c9007b",
            "0f5a862a66084b1d8329035d86342710",
            "a98007c6be8e457e8aab377081b4067a",
            "db6b3a3eb246430f893672cba2237be7",
            "896f1700b0ea41f8aa71a8a96fa2e1ab",
            "578fe2511d4a499ca4c0604028180f7f",
            "efb6ff38eff340f7bd3aa8a2541e9aa4",
            "5d78c59aac2141e1a3eea2afa4a38864",
            "6086da6fda794d88b14d8f6ebe54d985",
            "a0966340d8ec4dcead1d7a8710f33e55",
            "d373ca68ce5f45a892265e0d148f3e31",
            "5ef971880ff941c097647fee1933169e",
            "6b6ad3278b7a442eadbab3c3d699a076",
            "b66a31075fb04097828300b9af0a9691",
            "3c9bb8a2756c412487a70e72a3bf97fa",
            "de80395e045942daa24b115f73a79943",
            "6807d06866dc4095b82dafc750fc6928",
            "61e65e83a1a64790b07cb67d893d5648",
            "605142c887cc4615939a7d220f272e53",
            "f5d6868103ad4547b9666f5fa685d58a",
            "1eb6099409fa4c4b90939f73a2bbc28a",
            "518488427e1b4e849b4fae5348390668",
            "862bc105cd9e43279d84bf2b000c9a7f",
            "86a0c0d7c0cb439391ab4def06b43fee",
            "900eb2227ae042baaf876e05f1fa8122",
            "2b15f9e834b544c39d18d70ae06e4929",
            "0aa4bad540a84417a5a0dba8586748e6",
            "d3898d03644b43af9623b491e679adf5",
            "ebd7676682244906a1f6cd122294eed5",
            "d331bc04a3b9423d8909619b39166fdc",
            "a57474b011f943ef8f277f2a7123e656",
            "7f5e765266154ad1814cf77d5be73cef",
            "0f4afc8670204e4e8376d836058a7a2b",
            "c1f7b43b2f704d10b9120c04b15394c0",
            "17c90dac19e649fa9b048cd51f9e818f",
            "ff7168686dc04482b23ec61b59064d70",
            "de7352ca14bc472180b8ff1ba47fd507",
            "87c3b8e559ed4dbfad0b09a4ad0a70fa",
            "7b5d12c5c9b44541b3b522ed3de4edff",
            "ae14d4ad3d6e40a582140eeca7e92b4d",
            "eb50f88104a14f1bb844c5254e95c339",
            "e23e21394d234b6ebc0e44153e0589f1",
            "0c864db0116d4299a0f5cf8594d431b4",
            "a512229432bf41b585d7c5fbe9dc2c53",
            "59e6cdd18931457eb9b504f7bf4b6b0c",
            "d25ff4bdb45742ac8722fd6e10ff1925",
            "6b7d6d5e61094ec2b18a7daf4de85852",
            "b72747391fb745cd93c5dd7484c4ecbb",
            "8bf120fd36ce48c2a2312ca0e86d9ce7",
            "a6c2a5988da44b50b43ee12ab10d061e",
            "8b5d09e7b6b34aa89f6bd03b2aa14bc8",
            "46baf9e296c34c62bd199990c1711930",
            "4288a7dbe4a44ac89139bd82c463b110",
            "66a4580050154159932f86815f0486fc",
            "9ea0a9f844794790a88c3bbeae430b25",
            "d6e9389af48e4c49bdcb508c6dca0873",
            "c4b0b7ef506c4ca2b4a74123c0ca394f",
            "72f1ac8c4df2479f84d1a3c478584a1b",
            "c89a158b33b8416e900a06a21236e144",
            "bd7cf47bce224d54b180c797f1ada05f",
            "6feb678dfb00450b9e3dff020decd3e2",
            "63cefba8ffc04203873de4fa92193cb3",
            "c36a3f0649b7411185fb84d17d7cdfcb",
            "b3d05a6bc3eb44c68ae4f86ac0bcd556",
            "76c39042117a47b384c91d401808e6ae",
            "d3fa99832ffd4824a7b3b08e527146aa",
            "d5f102e4060f450ba86173a0fb4a66db",
            "0d6af56ad4b14da58a72bddde4b7d5d3",
            "9dd3b131580a475495caa5336b79309b",
            "d4c44b679440448e9f4b6c5d068f44f9",
            "55274e0253c7477d8fcb2e4d77782fb2",
            "478787bbf4fe4d8e8f21f59aaf4b3006",
            "321cb11fc086472b849ee2ae084b6247",
            "ff65b151128d431daa68c07c3f494ebc",
            "995b957e947f4b46aea9d2f92a4ba5ba",
            "71d987f2a5e54514a6fed0fbe3b15b19",
            "986e3d5e115641f58edc1f63106d47cf",
            "27515d8d8d244b368b983ad27a2cb45e",
            "1d08078f6873460ab658b1b567ab949e",
            "d870c7da4d004751beb0e1c5496c1216",
            "f5166344760b4cc99f0b7228c66d624a",
            "051ba6b7d21d41909e1a5b5bae623847",
            "8f12110c9b8a4983bed0e0ee9142c24e",
            "77a1a3a0d6cd440986b353325dcdf3d4",
            "b128f7c71ddc49ad87c7c93f15df34da",
            "3a046f5278e24562af540d348ded89ab",
            "f79a8eac337540a1b4e83bf509203b07",
            "f3d77e2d992141ca94e47bf64e8b6a26",
            "67c3e767587249ee81c487e7f1489cfb",
            "f069b735352b4890bccbbb8da95fdac3",
            "4e2a9fc893c9420cb5c7a5a3e7812b1c",
            "6b3220be48ae4257a9f630c88ce62edc",
            "f7d79206a9c84336bd4c90de07a71521",
            "1ddaa25a55124313aff8561efbf9912b",
            "2153814289be4456b871b6737402584b",
            "fce54867b04e45c49264cd6a97ce5a29",
            "daebbc0125fa4cdf9c231def63a582e2",
            "e919ebf252e4468db56a13fb13244835",
            "71ef649182b041d689b22a0738d5d692",
            "f657a57535b44b4a8513641744878c96",
            "b06a4201da0644f59c11426e1a7f3810",
            "29e5ccbdd52e49a7b64e994d3fcfbee8",
            "edc26d9224684ca6a95c1e9b59dc18d9",
            "3ac57e2babab46a08a13952392595e82",
            "a9cac2225a3c4767b591e6a916d8ecc7",
            "dc6b41e2a11a4407948e7a773901ff00",
            "739bdd398a76430b8a00a21ab1989050",
            "933f1ceaac7c4c12aa4b2a86ca13e7e9",
            "e3e36da14a184bc3ac3307ca9d15fb98",
            "43eb464b62cf404998ccb0877edae7d8",
            "2b092f8dda324a12ad8ee69f694b0256"
          ]
        },
        "id": "6FbPgtEBMaKn",
        "outputId": "496294b4-39d1-4d86-e1b9-8a2b1a965f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08bc00f1a80b44a79e5571f1d8a61d6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da56cac4c7c04d9ebe9ff776871abc90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0/41 [00:00<?, ?files/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6ced3e696144e1389f81780333a73ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00000-of-00041.parquet:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b909b6e40594508a0c43bce11141350"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00001-of-00041.parquet:   0%|          | 0.00/351M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea4d4e6bda6b41db9b4b2f4a7e2c87e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00002-of-00041.parquet:   0%|          | 0.00/329M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97149ea2677e4010b6a9619bc252277d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00003-of-00041.parquet:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1abe937a3eec48848e7c851278215f0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00004-of-00041.parquet:   0%|          | 0.00/307M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab7c129d81c24158b1169ce1372af650"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00005-of-00041.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da1b47d8091a46fcab7ca792a2144628"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00006-of-00041.parquet:   0%|          | 0.00/266M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6960eedba671403cb138d64f43d411a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00007-of-00041.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "236be4e2a67f439696574848f49858f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00008-of-00041.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ea74a54d5bd4a05a72ea66adc45c4ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00009-of-00041.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "453d2115fdec4e14992f162369e3095e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00010-of-00041.parquet:   0%|          | 0.00/234M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fed91a1267f14dc19b449c09ff34b136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00011-of-00041.parquet:   0%|          | 0.00/232M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00686fa5e7684241881b119288c5dd47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00012-of-00041.parquet:   0%|          | 0.00/239M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffe12739182c4d78ae3bd47cc63918ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00013-of-00041.parquet:   0%|          | 0.00/241M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23cbf53cfefa427ebcddd28fcb679318"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00014-of-00041.parquet:   0%|          | 0.00/223M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02d81549a62428d9835701ea469b829"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00015-of-00041.parquet:   0%|          | 0.00/235M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22f1b7aebecd4fffb56293345ea1b57a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00016-of-00041.parquet:   0%|          | 0.00/503M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e7787bcb2c64d44ae1ff498ea543176"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00017-of-00041.parquet:   0%|          | 0.00/231M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99717cc88b184841b58ebe738d40193f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00018-of-00041.parquet:   0%|          | 0.00/231M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7fa9d9af2d441ed9466aed31eee6aaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00019-of-00041.parquet:   0%|          | 0.00/195M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1de2b99d922c47ef805c4996a0049fc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00020-of-00041.parquet:   0%|          | 0.00/225M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5525e38849d4b06be38dbf6d69b56d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00021-of-00041.parquet:   0%|          | 0.00/216M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a537ae83747540c2b54d88f59de558ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00022-of-00041.parquet:   0%|          | 0.00/202M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43e3f920b3ad4fe198cb49a71a4a3aab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00023-of-00041.parquet:   0%|          | 0.00/213M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "862ccd7856f244f0a2a3cac391c8700c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00024-of-00041.parquet:   0%|          | 0.00/221M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a843e7a9a94c4ffdb041c0dd6e70e76f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00025-of-00041.parquet:   0%|          | 0.00/221M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34b754ec5b6741bdb80e44a244f11199"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00026-of-00041.parquet:   0%|          | 0.00/208M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98adba4b5ec74c5eafafd5212490f204"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00027-of-00041.parquet:   0%|          | 0.00/214M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "819bb85691fc430c85b8cd72dc7f3f22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00028-of-00041.parquet:   0%|          | 0.00/188M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c89590613872439fa134c0efbc930e29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00029-of-00041.parquet:   0%|          | 0.00/218M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "407a8aae48074e2a90edd6d49a9eb2ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00030-of-00041.parquet:   0%|          | 0.00/204M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bb3b8145c6f41f4a3f23e895ff74359"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00031-of-00041.parquet:   0%|          | 0.00/215M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6df658caa4244c7805ecc7a60aee7f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00032-of-00041.parquet:   0%|          | 0.00/214M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f5a862a66084b1d8329035d86342710"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00033-of-00041.parquet:   0%|          | 0.00/203M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b6ad3278b7a442eadbab3c3d699a076"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00034-of-00041.parquet:   0%|          | 0.00/219M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86a0c0d7c0cb439391ab4def06b43fee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00035-of-00041.parquet:   0%|          | 0.00/224M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17c90dac19e649fa9b048cd51f9e818f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00036-of-00041.parquet:   0%|          | 0.00/610M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d25ff4bdb45742ac8722fd6e10ff1925"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00037-of-00041.parquet:   0%|          | 0.00/674M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4b0b7ef506c4ca2b4a74123c0ca394f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00038-of-00041.parquet:   0%|          | 0.00/538M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d6af56ad4b14da58a72bddde4b7d5d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00039-of-00041.parquet:   0%|          | 0.00/465M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d08078f6873460ab658b1b567ab949e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20231101.en/train-00040-of-00041.parquet:   0%|          | 0.00/422M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f069b735352b4890bccbbb8da95fdac3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/6407814 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b06a4201da0644f59c11426e1a7f3810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: 5000 Wikipedia pages\n",
            "Sample page: Anarchism\n",
            "Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation-states, and capitalism. Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations. As a historically left-wing movement, this reading of anarchism is placed on the farthest left of the political spectrum, usually described as ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG pipelines typically split long documents into chunks so that:\n",
        "\n",
        "Each chunk can be embedded efficiently.\n",
        "\n",
        "Retrieval can return only relevant parts.\n",
        "\n",
        "LLM context window does not overflow.\n",
        "\n",
        "We make a simple fixed-size chunker, which is fine for demos.\n",
        "(Production systems may use token-based or semantic chunking.)"
      ],
      "metadata": {
        "id": "ss1i99C3QtXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "def chunk_text(text, chunk_size=700, overlap=100):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "        chunks.append(chunk)\n",
        "        start = end - overlap  # ensure overlap for coherence\n",
        "    return chunks\n",
        "\n",
        "docs = []\n",
        "for row in wiki:\n",
        "    text = row[\"text\"]\n",
        "    if not text:\n",
        "        continue\n",
        "    chunks = chunk_text(text)\n",
        "    for chunk in chunks:\n",
        "        docs.append(Document(page_content=chunk))\n",
        "\n",
        "print(\"Total chunks created:\", len(docs))\n",
        "print(\"Example chunk:\\n\", docs[0].page_content[:300], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dmZ0Yi5OQ95",
        "outputId": "391a78dc-69f6-4682-ef4f-d4d601e6ab3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks created: 119038\n",
            "Example chunk:\n",
            " Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation-states, and capitalism. Anarchism advocates for the replacement of the state  ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use:\n",
        "\n",
        "sentence-transformers/all-MiniLM-L6-v2\n",
        "Light & fast; great for RAG demos.\n",
        "\n",
        "FAISS for similarity search\n",
        "\n",
        "We embed all document chunks, then build the FAISS index."
      ],
      "metadata": {
        "id": "CL64XQZGQ4m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
        "\n",
        "# Build the FAISS vector store\n",
        "vector_store = FAISS.from_documents(docs, embeddings)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "print(\"Vector store ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "dalZnOEyMgAh",
        "outputId": "745fce12-9a31-4a56-c587-51716780cf58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.fastspeech2_conformer.configuration_fastspeech2_conformer because of the following error (look up to see its traceback):\nNo module named 'transformers.models.fastspeech2_conformer.configuration_fastspeech2_conformer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_gptqmodel_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gptqmodel_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.fastspeech2_conformer.configuration_fastspeech2_conformer'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-585575072.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0membedding_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sentence-transformers/all-MiniLM-L6-v2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Build the FAISS vector store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                         \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 obj.__init__ = functools.wraps(obj.__init__)(  # type: ignore[misc]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m             ) from exc\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         self.client = sentence_transformers.SentenceTransformer(\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0;34m\"xlm-roberta-large-finetuned-conll02-dutch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;34m\"xlm-roberta-large-finetuned-conll02-spanish\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0;34m\"xlm-roberta-large-finetuned-conll03-english\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0;34m\"xlm-roberta-large-finetuned-conll03-german\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;34m\"xlm-roberta-large\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtruncate_sentence_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m         \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     54\u001b[0m             model is cased or not)\n\u001b[1;32m     55\u001b[0m         \u001b[0mtokenizer_name_or_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mName\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mWhen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBackend\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mCan\u001b[0m \u001b[0mbe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mopenvino\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefault\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir, **model_args)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mconfig_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0mkwargs_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0;31m# ensure not to pollute the config object with dtype=\"auto\" - since it's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0;31m# meaningless in the context of the config object - torch.dtype values are acceptable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_generation_mixin_to_remote_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \"\"\"\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mAdds\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGenerationMixin\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minheritance\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mPyTorch\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbackwards\u001b[0m \u001b[0mcompatibility\u001b[0m \u001b[0mpurposes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv4\u001b[0m\u001b[0;36m.45\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mve\u001b[0m \u001b[0mstarted\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdeprecation\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not find {attr} in {transformers_module}!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_generation_mixin_to_remote_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;31m# Now we need to copy and re-register `from_config` and `from_pretrained` as class methods otherwise we can't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m     \u001b[0;31m# have a specific docstrings for them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m     \u001b[0mfrom_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseAutoModelClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0mfrom_config_docstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsert_head_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFROM_CONFIG_DOCSTRING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_qutlass_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_qutlass_available\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_qutlass_version\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0.1.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_compressed_tensors_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_gptqmodel_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_gptqmodel_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_eetq_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.fastspeech2_conformer.configuration_fastspeech2_conformer because of the following error (look up to see its traceback):\nNo module named 'transformers.models.fastspeech2_conformer.configuration_fastspeech2_conformer'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the Gemma-3 model through Hugging Face Transformers.\n",
        "If this exact model name is not yet published, substitute any Gemma model such as:\n",
        "\n",
        "\"google/gemma-2-2b\"\n",
        "\n",
        "\"google/gemma-7b\"\n",
        "\n",
        "\"google/gemma-3-4b\" (if available)\n",
        "\n",
        "We wrap it using HuggingFacePipeline to integrate it with LangChain."
      ],
      "metadata": {
        "id": "Rk_fR2o5RB4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "model_name = \"google/gemma-3-4b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "\n",
        "gen_pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=350,\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=gen_pipe)\n",
        "print(\"Gemma-3 Loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "z4u5VrZyMms_",
        "outputId": "4a98b6c8-0a03-479e-a982-c0cbec366005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.llms'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1214354061.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFacePipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"google/gemma-3-4b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.llms'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now connect:\n",
        "\n",
        "Retriever (FAISS)\n",
        "\n",
        "LLM (Gemma-3)\n",
        "\n",
        "Simple “stuff” chain (concatenate retrieved chunks)\n",
        "\n",
        "LangChain’s RetrievalQA handles this."
      ],
      "metadata": {
        "id": "nA4cnY8hRPjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "print(\"RAG system ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "LS3B-XiQM9_a",
        "outputId": "13aa461d-68ae-4f23-8e8c-0b81ae092626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.chains'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3698580067.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRetrievalQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m qa = RetrievalQA.from_chain_type(\n\u001b[1;32m      4\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stuff\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.chains'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now run the same example questions provided earlier:\n",
        "\n",
        "Example Queries\n",
        "\n",
        "“Explain the history and major events of the Roman Empire.”\n",
        "\n",
        "“What are the main differences between mitosis and meiosis?”\n",
        "\n",
        "“List best practices for storing sensitive data securely.”\n",
        "\n",
        "“Summarize the key concepts from the article titled ‘Quantum entanglement and Bell inequalities’.”\n",
        "\n",
        "“Given documentation excerpt… generate an FAQ.”\n",
        "\n",
        "“MCQ: What does a seismograph measure?”\n",
        "\n",
        "We will evaluate:\n",
        "\n",
        "Retrieved documents\n",
        "\n",
        "Model answer\n",
        "\n",
        "Time taken\n",
        "\n",
        "Simple rough token counts (input + output)"
      ],
      "metadata": {
        "id": "KGUrZMkYRaOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def count_tokens(text):\n",
        "    # Approximate token count using whitespace split (cheap + OK for demo)\n",
        "    return len(text.split())\n",
        "\n",
        "def run_query(query):\n",
        "    print(\"=\"*70)\n",
        "    print(\"QUERY:\", query)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    start = time.time()\n",
        "    result = qa(query)\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    answer = result[\"result\"]\n",
        "    sources = result[\"source_documents\"]\n",
        "\n",
        "    # collect metrics\n",
        "    retrieved_text = \"\\n\".join([s.page_content for s in sources])\n",
        "    input_tokens = count_tokens(retrieved_text) + count_tokens(query)\n",
        "    output_tokens = count_tokens(answer)\n",
        "\n",
        "    print(\"\\n--- ANSWER ---\\n\", answer)\n",
        "    print(\"\\n--- SOURCES (first 300 chars each) ---\")\n",
        "    for i, s in enumerate(sources):\n",
        "        print(f\"[{i}] {s.page_content[:300]} ...\\n\")\n",
        "\n",
        "    print(\"--- METRICS ---\")\n",
        "    print(\"Time (sec):\", round(elapsed, 3))\n",
        "    print(\"Approx input tokens:\", input_tokens)\n",
        "    print(\"Approx output tokens:\", output_tokens)\n",
        "    print()"
      ],
      "metadata": {
        "id": "lHsgjpodM_JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run All Example Queries**"
      ],
      "metadata": {
        "id": "MupXhPS5Rl_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"Explain the history and major events of the Roman Empire.\",\n",
        "    \"What are the main differences between mitosis and meiosis?\",\n",
        "    \"List best practices for storing sensitive data securely.\",\n",
        "    \"Summarize key concepts from the article titled 'Quantum entanglement and Bell inequalities'.\",\n",
        "    \"Generate a short FAQ answer for users needing to comply with chemical safety standards.\",\n",
        "    \"What does a seismograph measure? Choose from A) Earthquakes B) Rainfall C) Sunlight D) Temperature.\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    run_query(q)"
      ],
      "metadata": {
        "id": "B8X7QmEHNDfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook’s metrics include:\n",
        "\n",
        "Latency\n",
        "\n",
        "Approx token counts\n",
        "\n",
        "To estimate energy:\n",
        "\n",
        "You can instrument GPU power using nvidia-smi --query-gpu=power.draw --format=csv in a loop during inference.\n",
        "But even without exact measurement, you can rely on typical per-token energy usage for 2–4B-parameter models (~low Wh per query).\n",
        "\n",
        "Collected metrics:\n",
        "\n",
        "input tokens ≈ amount of text retrieved + query tokens.\n",
        "\n",
        "output tokens ≈ LLM answer.\n",
        "\n",
        "Energy tends to scale with total tokens processed."
      ],
      "metadata": {
        "id": "BrPyzkWXRxUk"
      }
    }
  ]
}